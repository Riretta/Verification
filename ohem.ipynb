{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLL_OHEM(torch.nn.NLLLoss):\n",
    "    \"\"\" Online hard example mining.\n",
    "    Needs input from nn.LogSotmax() \"\"\"\n",
    "\n",
    "    def __init__(self, ratio):\n",
    "        super(NLL_OHEM, self).__init__(None, True)\n",
    "        self.ratio = ratio\n",
    "\n",
    "    def forward(self, x, y, ratio=None):\n",
    "        if ratio is not None:\n",
    "            self.ratio = ratio\n",
    "        num_inst = x.size(0)\n",
    "        num_hns = int(self.ratio * num_inst)\n",
    "        x_ = x.clone()\n",
    "        inst_losses = torch.zeros(num_inst)\n",
    "        for idx, label in enumerate(y.data):\n",
    "            inst_losses[idx] = -x_.data[idx, label]\n",
    "            # loss_incs = -x_.sum(1)\n",
    "        _, idxs = inst_losses.topk(num_hns)\n",
    "        x_hn = x.index_select(0, idxs)\n",
    "        y_hn = y.index_select(0, idxs)\n",
    "        return torch.nn.functional.nll_loss(x_hn, y_hn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hard_example_mining(dist_mat, labels, return_inds=False):\n",
    "    \"\"\"For each anchor, find the hardest positive and negative sample.\n",
    "    Args:\n",
    "      dist_mat: pytorch Variable, pair wise distance between samples, shape [N, N]\n",
    "      labels: pytorch LongTensor, with shape [N]\n",
    "      return_inds: whether to return the indices. Save time if `False`(?)\n",
    "    Returns:\n",
    "      dist_ap: pytorch Variable, distance(anchor, positive); shape [N]\n",
    "      dist_an: pytorch Variable, distance(anchor, negative); shape [N]\n",
    "      p_inds: pytorch LongTensor, with shape [N];\n",
    "        indices of selected hard positive samples; 0 <= p_inds[i] <= N - 1\n",
    "      n_inds: pytorch LongTensor, with shape [N];\n",
    "        indices of selected hard negative samples; 0 <= n_inds[i] <= N - 1\n",
    "    NOTE: Only consider the case in which all labels have same num of samples,\n",
    "      thus we can cope with all anchors in parallel.\n",
    "    \"\"\"\n",
    "\n",
    "    assert len(dist_mat.size()) == 2\n",
    "    assert dist_mat.size(0) == dist_mat.size(1)\n",
    "    N = dist_mat.size(0)\n",
    "\n",
    "    # shape [N, N]\n",
    "    is_pos = labels.expand(N, N).eq(labels.expand(N, N).t())\n",
    "    is_neg = labels.expand(N, N).ne(labels.expand(N, N).t())\n",
    "\n",
    "    # `dist_ap` means distance(anchor, positive)\n",
    "    # both `dist_ap` and `relative_p_inds` with shape [N, 1]\n",
    "    dist_ap, relative_p_inds = torch.max(\n",
    "        dist_mat[is_pos].contiguous().view(N, -1), 1, keepdim=True)\n",
    "    # `dist_an` means distance(anchor, negative)\n",
    "    # both `dist_an` and `relative_n_inds` with shape [N, 1]\n",
    "    dist_an, relative_n_inds = torch.min(\n",
    "        dist_mat[is_neg].contiguous().view(N, -1), 1, keepdim=True)\n",
    "    # shape [N]\n",
    "    dist_ap = dist_ap.squeeze(1)\n",
    "    dist_an = dist_an.squeeze(1)\n",
    "\n",
    "    if return_inds:\n",
    "        # shape [N, N]\n",
    "        ind = (labels.new().resize_as_(labels)\n",
    "               .copy_(torch.arange(0, N).long())\n",
    "               .unsqueeze(0).expand(N, N))\n",
    "        # shape [N, 1]\n",
    "        p_inds = torch.gather(\n",
    "            ind[is_pos].contiguous().view(N, -1), 1, relative_p_inds.data)\n",
    "        n_inds = torch.gather(\n",
    "            ind[is_neg].contiguous().view(N, -1), 1, relative_n_inds.data)\n",
    "        # shape [N]\n",
    "        p_inds = p_inds.squeeze(1)\n",
    "        n_inds = n_inds.squeeze(1)\n",
    "        return dist_ap, dist_an, p_inds, n_inds\n",
    "\n",
    "    return dist_ap, dist_an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hard_aware_point_2_set_mining(dist_mat, labels, weighting='poly', coeff=10):\n",
    "    \"\"\"For each anchor, weight the positive and negative samples according to the paper:\n",
    "    Yu, R., Dou, Z., Bai, S., Zhang, Z., Xu1, Y., & Bai, X. (2018). Hard-Aware Point-to-Set Deep Metric for Person Re-identification, ECCV 2018.\n",
    "    Args:\n",
    "      dist_mat: pytorch Variable, pairwise distance between samples, shape [N, N]\n",
    "      labels: pytorch LongTensor, with shape [N] size (N,1)\n",
    "      weighting: str, weighting scheme, i.e., 'poly' or 'exp' => eq. (8) or (7) in the paper\n",
    "      coefficient: float, corresponds to the std or alpha parameters used in the paper\n",
    "    Returns:\n",
    "      dist_ap: pytorch Variable, distance(anchor, positive); shape [N]\n",
    "      dist_an: pytorch Variable, distance(anchor, negative); shape [N]\n",
    "    NOTE: Only consider the case in which all labels have same num of samples,\n",
    "      thus we can cope with all anchors in parallel.\n",
    "    \"\"\"\n",
    "\n",
    "    N = dist_mat.size(0)\n",
    "    # shape [N, N]\n",
    "    is_pos = labels.expand(N, N).eq(labels.expand(N, N).t()) \n",
    "    is_neg = labels.expand(N, N).ne(labels.expand(N, N).t())\n",
    "    \n",
    "    # Exclude selfs for positive samples\n",
    "    device = labels.device\n",
    "    v = torch.zeros(N).to(device).type(is_pos.dtype)\n",
    "    mask = torch.diag(torch.ones_like(v)).to(device).type(is_pos.dtype)\n",
    "    is_pos = mask * torch.diag(v) + (1. - mask) * is_pos\n",
    "\n",
    "    # `dist_ap` means distance(anchor, positive)\n",
    "    dist_ap = dist_mat[is_pos].contiguous().view(N, -1)\n",
    "    # `dist_an` means distance(anchor, negative)\n",
    "    dist_an = dist_mat[is_neg].contiguous().view(N, -1)\n",
    "    # Weighting scheme\n",
    "    if weighting == 'poly':\n",
    "        w_ap = torch.pow(dist_ap + 1, coeff)\n",
    "        w_an = torch.pow(dist_an + 1, -2 * coeff)\n",
    "    else:\n",
    "        w_ap = torch.exp(dist_ap / coeff)\n",
    "        w_an = torch.exp(-dist_an / coeff)\n",
    "\n",
    "    dist_ap = torch.sum(dist_ap * w_ap, dim=1) / torch.sum(w_ap, dim=1)\n",
    "    dist_an = torch.sum(dist_an * w_an, dim=1) / torch.sum(w_an, dim=1)\n",
    "    return dist_ap, dist_an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
