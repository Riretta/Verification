{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from ResNetCaps_E.ipynb\n",
      "importing Jupyter notebook from MiniBatch_generator.ipynb\n",
      "importing Jupyter notebook from losses.ipynb\n",
      "importing Jupyter notebook from ohem.ipynb\n",
      "importing Jupyter notebook from CHIMP_DataLoader.ipynb\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import csv\n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torchsummary import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import time\n",
    "import os\n",
    "import pathlib\n",
    "import copy\n",
    "from datetime import date\n",
    "\n",
    "import import_ipynb\n",
    "import ResNetCaps_E\n",
    "import MiniBatch_generator\n",
    "import losses\n",
    "import CHIMP_DataLoader\n",
    "\n",
    "ATET_use = False\n",
    "LFW_use = True\n",
    "CHIM_use = False\n",
    "\n",
    "load_model = False\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATASET INITIALIZATION -----------------------------------------------------\n",
    "if ATET_use:\n",
    "    folder = 'ATET'\n",
    "    dataset_folder = \"ATeT_faces/orl_faces/\"\n",
    "if LFW_use:\n",
    "    folder = 'LFW'\n",
    "    dataset_folder = \"lfw/\"\n",
    "if CHIM_use:\n",
    "    folder = 'CHIM'\n",
    "    dataset_folder = \"chimpanzee_faces-master/datasets_cropped_chimpanzee_faces/data_CZoo/annotations_czoo.txt\"   \n",
    "    \n",
    "\n",
    "dataset_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),        \n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
    "])\n",
    "\n",
    "dataset_folder = os.path.join(\"/home/rita/JupyterProjects/EYE-SEA/DataSets/Verification\", dataset_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LFW dataset\n"
     ]
    }
   ],
   "source": [
    "if CHIM_use:\n",
    "    print('Loading chimp dataset')\n",
    "    dataset = CHIMP_DataLoader.Chimp_Dataset(dataset_folder,dataset_transform,0.8)\n",
    "    dataset_t = CHIMP_DataLoader.Chimp_Dataset(dataset_folder,dataset_transform,0.8,train=False)\n",
    "else:\n",
    "    print('Loading {} dataset'.format(folder))\n",
    "    dataset = MiniBatch_generator.mini_batch(dataset_folder, dataset_transform,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new model\n"
     ]
    }
   ],
   "source": [
    "#MODEL LOADER ---------------------------------- \n",
    "\n",
    "PATH= os.path.join(os.getcwd(),os.path.join('Log_model/HAP2S',folder,'DIGIT/',(date.today()).isoformat()))\n",
    "pathlib.Path(PATH).mkdir(parents=True, exist_ok=True)\n",
    "if len(os.listdir(PATH)) > 2 and load_model:\n",
    "    print('Loading model from PATH: {}'.format(PATH))\n",
    "    model = ResNetCaps_E.ResNetCaps_E(DigitEnd=False)\n",
    "    if pick_model == -1:\n",
    "        init = len(os.listdir(PATH))-2        \n",
    "        model.load_state_dict(torch.load(os.path.join(PATH,str(init))))\n",
    "    else:\n",
    "        model.load_state_dict(torch.load(os.path.join(PATH,str(pick_model))))\n",
    "        init = pick_model\n",
    "    model.eval()\n",
    "else:\n",
    "    print('Creating a new model')\n",
    "    init=0\n",
    "    model = ResNetCaps_E.ResNetCaps_E()\n",
    "\n",
    "selected = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNetCaps_E.ResNetCaps_E(DigitEnd=True)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "    model = nn.DataParallel(model)\n",
    "    \n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),lr = 0.001)\n",
    "criterion = losses.HAP2STripletLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1:100\n",
      "torch.Size([846, 846])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ResNetCaps_E.ipynb:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"from torch.utils.data import Dataset, DataLoader\\n\",\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[846, -1]' is invalid for input of size 16930",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-327d07067add>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0memb_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memb_a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mloss_collect\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/JupyterProjects/EYE-SEA/Verification_RNCAPS/losses.ipynb\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, feats, targets)\u001b[0m\n",
      "\u001b[0;32m~/JupyterProjects/EYE-SEA/Verification_RNCAPS/ohem.ipynb\u001b[0m in \u001b[0;36mhard_aware_point_2_set_mining\u001b[0;34m(dist_mat, labels, weighting, coeff)\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[846, -1]' is invalid for input of size 16930"
     ]
    }
   ],
   "source": [
    "#TRAINING PHASE ----------------------------------minibatch random everyepoch\n",
    "\n",
    "n_epochs = 100\n",
    "loss_list_b = []\n",
    "\n",
    "for epoch in range(n_epochs): \n",
    "    print('epoch {}:{}'.format(epoch+1, n_epochs)) \n",
    "    model.train()\n",
    "    loss_collect = 0\n",
    "    in_a,labels = dataset.prepare_batch()\n",
    "    in_a = torch.stack(in_a)\n",
    "    in_a = in_a.to(device)\n",
    "    labels = torch.Tensor(labels).to(device)\n",
    "\n",
    "    #Compute embeddings for anchor, positive, and negative images\n",
    "\n",
    "    emb_a = model(in_a)\n",
    "    emb_a = emb_a.view(in_a.size(0),-1)\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(emb_a.squeeze(),labels)\n",
    "    loss_collect +=loss.item()\n",
    "\n",
    "    print(\"lost per batch {}\".format(loss))\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_list_b.append(loss)\n",
    "    torch.save(model.state_dict(), os.path.join(PATH,str(epoch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(in_a.size())\n",
    "print(emb_a.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = np.arange(1,n_epochs+1)\n",
    "plt.plot(epochs, loss_list_b, color='pink')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('lost')\n",
    "plt.title('Training phase')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(feats,labels):\n",
    "    D = losses.euclidean_distance(feats,feats)\n",
    "    N = D.size(0)\n",
    "    print(N)\n",
    "    # shape [N, N]\n",
    "    is_pos = labels.expand(N, N).eq(labels.expand(N, N).t())\n",
    "    is_neg = labels.expand(N, N).ne(labels.expand(N, N).t())\n",
    "    \n",
    "    # Exclude selfs for positive samples\n",
    "    device = labels.device\n",
    "    v = torch.zeros(N).to(device).type(is_pos.dtype)\n",
    "    mask = torch.diag(torch.ones_like(v)).to(device).type(is_pos.dtype)\n",
    "    is_pos = mask * torch.diag(v) + (1. - mask) * is_pos\n",
    "\n",
    "    # `dist_ap` means distance(anchor, positive)\n",
    "    dist_ap = D[is_pos].contiguous().view(N, -1)\n",
    "    # `dist_an` means distance(anchor, negative)\n",
    "    dist_an = D[is_neg].contiguous().view(N, -1)\n",
    "    \n",
    "    threshold = (torch.mean(dist_ap) + torch.mean(dist_an))/2\n",
    "    \n",
    "    positives_True =  0\n",
    "    for i in dist_ap:\n",
    "        for j in range(len(i)):\n",
    "            if i[j].item() < threshold: positives_True += 1 \n",
    "    negatives_True =  0\n",
    "    for i in dist_an:\n",
    "        for j in range(len(i)):\n",
    "            if i[j].item() > threshold: negatives_True += 1   \n",
    "    \n",
    "    VAL = positives_True/dist_ap.numel()\n",
    "    FAR = negatives_True/dist_an.numel()\n",
    "    \n",
    "    return positives_True, negatives_True, VAL, FAR, threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "#test_minibatch \n",
    "\n",
    "in_a,labels = dataset.prepare_batch_test()\n",
    "in_a = torch.stack(in_a)\n",
    "in_a = in_a.to(device)\n",
    "labels = torch.Tensor(labels).to(device)\n",
    "emb_a = model(in_a)\n",
    "loss = criterion(emb_a.squeeze(),labels)\n",
    "P_T, N_T, VAL, FAR,th = accuracy(emb_a.squeeze(),labels)\n",
    "print(\"Loss {}. Threshold {}: P_T {} N_T {} VAL {} FAR {}\".format(loss, th, P_T, N_T, VAL, FAR))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
