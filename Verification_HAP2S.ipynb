{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import csv\n",
    "from skimage import io\n",
    "\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torchsummary import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "import import_ipynb\n",
    "import ResNetCaps_E\n",
    "import MiniBatch_generator\n",
    "import losses\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH= os.path.join(os.getcwd(),'Log_model/LFW/CLUSTER/')\n",
    "if not os.path.exists(PATH):\n",
    "     os.mkdir(PATH)\n",
    "\n",
    "selected = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNetCaps_E.ResNetCaps_E()\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "    model = nn.DataParallel(model)\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),lr = 0.001)\n",
    "criterion = losses.HAP2STripletLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),        \n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
    "])\n",
    "\n",
    "folder =\"/home/rita/JupyterProjects/EYE-SEA/DataSets/Verification/ATeT_faces/orl_faces/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train verification \n",
    "#minibatch created randomly each epoch MiniBatch_generator\n",
    "\n",
    "n_epochs = 10\n",
    "\n",
    "dataset = MiniBatch_generator.mini_batch(folder, dataset_transform,0.3)\n",
    "\n",
    "loss_list_b = []\n",
    "\n",
    "for epoch in range(n_epochs): \n",
    "    print('epoch {}:{}'.format(epoch+1, n_epochs)) \n",
    "    model.train()\n",
    "    loss_collect = 0\n",
    "    in_a,labels = dataset.prepare_batch()\n",
    "    in_a = torch.stack(in_a)\n",
    "    in_a = in_a.to(device)\n",
    "    labels = torch.Tensor(labels).to(device)\n",
    "\n",
    "    #Compute embeddings for anchor, positive, and negative images\n",
    "    print(len(in_a))\n",
    "    emb_a = model(in_a)\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(emb_a.squeeze(),labels)\n",
    "    loss_collect +=loss.item()\n",
    "\n",
    "    print(\"loss per batch {}\".format(loss))\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_list_b.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = np.arange(1,n_epochs+1)\n",
    "plt.plot(epochs, loss_list_b, color='pink')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.title('Training phase')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(feats,labels):\n",
    "    D = losses.euclidean_distance(feats,feats)\n",
    "    N = D.size(0)\n",
    "    print(N)\n",
    "    # shape [N, N]\n",
    "    is_pos = labels.expand(N, N).eq(labels.expand(N, N).t())\n",
    "    is_neg = labels.expand(N, N).ne(labels.expand(N, N).t())\n",
    "    \n",
    "    # Exclude selfs for positive samples\n",
    "    device = labels.device\n",
    "    v = torch.zeros(N).to(device).type(is_pos.dtype)\n",
    "    mask = torch.diag(torch.ones_like(v)).to(device).type(is_pos.dtype)\n",
    "    is_pos = mask * torch.diag(v) + (1. - mask) * is_pos\n",
    "\n",
    "    # `dist_ap` means distance(anchor, positive)\n",
    "    dist_ap = D[is_pos].contiguous().view(N, -1)\n",
    "    # `dist_an` means distance(anchor, negative)\n",
    "    dist_an = D[is_neg].contiguous().view(N, -1)\n",
    "    \n",
    "    threshold = (torch.mean(dist_ap) + torch.mean(dist_an))/2\n",
    "    \n",
    "    positives_True =  0\n",
    "    for i in dist_ap:\n",
    "        for j in range(len(i)):\n",
    "            if i[j].item() < threshold: positives_True += 1 \n",
    "    negatives_True =  0\n",
    "    for i in dist_an:\n",
    "        for j in range(len(i)):\n",
    "            if i[j].item() > threshold: negatives_True += 1   \n",
    "    \n",
    "    VAL = positives_True/dist_ap.numel()\n",
    "    FAR = negatives_True/dist_an.numel()\n",
    "    \n",
    "    return positives_True, negatives_True, VAL, FAR, threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "#test_minibatch \n",
    "\n",
    "in_a,labels = dataset.prepare_batch_test()\n",
    "in_a = torch.stack(in_a)\n",
    "in_a = in_a.to(device)\n",
    "labels = torch.Tensor(labels).to(device)\n",
    "emb_a = model(in_a)\n",
    "loss = criterion(emb_a.squeeze(),labels)\n",
    "P_T, N_T, VAL, FAR,th = accuracy(emb_a.squeeze(),labels)\n",
    "print(\"Loss {}. Threshold {}: P_T {} N_T {} VAL {} FAR {}\".format(loss, th, P_T, N_T, VAL, FAR))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
