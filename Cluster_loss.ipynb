{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import csv\n",
    "from skimage import io\n",
    "\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torchsummary import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import time\n",
    "import pathlib\n",
    "import os\n",
    "import copy\n",
    "from datetime import date\n",
    "\n",
    "import import_ipynb\n",
    "import ResNetCaps_E\n",
    "import Dataset_Loader\n",
    "import losses\n",
    "\n",
    "verbose = False\n",
    "load_model = False\n",
    "LFW_use = False\n",
    "ATET_use = True\n",
    "folder = 'ATET'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    print('CUDA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),        \n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
    "])\n",
    "\n",
    "#folderDataset = \"/home/rita/JupyterProjects/EYE-SEA/DataSets/Verification/ATeT_faces/orl_faces/\"\n",
    "folderDataset = \"/home/rita/JupyterProjects/EYE-SEA/DataSets/Verification/lfw/\"\n",
    "#folderDataset = \"/media/Data/rita/EYE-SEA/Verification/Datasets/ATeT_faces/orl_faces/\"\n",
    "batch_size = 130\n",
    "\n",
    "Train_loader = Dataset_Loader.Folded_Dataset(folderDataset, dataset_transform,0.8)\n",
    "dataLoader_generator = torch.utils.data.DataLoader(Train_loader,batch_size=batch_size)\n",
    "Test_loader = Dataset_Loader.Folded_Dataset(folderDataset, dataset_transform,0.8,train = False)\n",
    "dataLoader_generator_test = torch.utils.data.DataLoader(Test_loader,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH= os.path.join(os.getcwd(),os.path.join('Log_model/Cluster_Loss',folder,'DIGIT/',(date.today()).isoformat()))\n",
    "pathlib.Path(PATH).mkdir(parents=True, exist_ok=True)\n",
    "if len(os.listdir(PATH)) > 2 and load_model:\n",
    "    print('Loading model from PATH: {}'.format(PATH))\n",
    "    model = ResNetCaps_E.ResNetCaps_E(DigitEnd=False)\n",
    "    if pick_model == -1:\n",
    "        init = len(os.listdir(PATH))-2        \n",
    "        model.load_state_dict(torch.load(os.path.join(PATH,str(init))))\n",
    "    else:\n",
    "        model.load_state_dict(torch.load(os.path.join(PATH,str(pick_model))))\n",
    "        init = pick_model\n",
    "    model.eval()\n",
    "else:\n",
    "    print('Creating a new model')\n",
    "    init=0\n",
    "    model = ResNetCaps_E.ResNetCaps_E()\n",
    "    \n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "    model = nn.DataParallel(model)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusterLoss(nn.Module):\n",
    "    def __init__(self,alpha=0.2):\n",
    "        super(ClusterLoss,self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.ranking_loss = nn.SoftMarginLoss()\n",
    "        \n",
    "        self.clusters_sum = []\n",
    "        self.clusters_count = []\n",
    "        self.clusters_labels = []\n",
    "        \n",
    "    def forward(self,feats,targets):       \n",
    "       \n",
    "        t_intra,D_intra = self.Euclidean_intra(feats,targets)\n",
    "        t_inter,D_inter = self.Euclidean_inter(targets)\n",
    "        \n",
    "        Y = (torch.Tensor(t_intra).data.new().resize_as_(torch.Tensor(t_intra).data).fill_(1))\n",
    "        Y = Y.to(device)\n",
    "        loss = self.ranking_loss((D_intra-D_inter)+self.alpha,Y)\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "    def mean_feats(self,feats,targets):\n",
    "        N = feats.size(0)\n",
    "        \n",
    "        # shape [N, N]\n",
    "        is_pos = targets.expand(N, N).eq(targets.expand(N, N).t())\n",
    "        is_neg = targets.expand(N, N).ne(targets.expand(N, N).t())\n",
    "        \n",
    "        target_batch = []\n",
    "        for i in range(N):\n",
    "            t = targets[i]\n",
    "            if not t in target_batch:\n",
    "                a = feats[is_pos[:,i],:]#list of features computed over the same individual\n",
    "                sum_a = torch.sum(a,dim=0)              \n",
    "\n",
    "                if self.clusters_sum:\n",
    "                    if self.clusters_labels:                       \n",
    "                        if t in self.clusters_labels:\n",
    "                            j = self.clusters_labels.index(t.item())\n",
    "                            self.clusters_sum[j] += sum_a\n",
    "                            self.clusters_count[j] += a.size(0)\n",
    "                        else:\n",
    "                            self.clusters_sum.append(sum_a)\n",
    "                            self.clusters_labels.append(t)\n",
    "                            self.clusters_count.append(a.size(0))\n",
    "                    else: \n",
    "                        print('There are no labels {}'.format(M_label))\n",
    "                else:\n",
    "\n",
    "                    self.clusters_sum.append(sum_a)\n",
    "                    self.clusters_labels.append(t.item())\n",
    "                    self.clusters_count.append(a.size(0))\n",
    "                target_batch.append(t)\n",
    "                \n",
    "    def mean_feats_compute(self):\n",
    "       \n",
    "        M_emb = [sum_a/len_a for sum_a,len_a in zip(self.clusters_sum,self.clusters_count)]\n",
    "        self.M_emb = torch.stack(M_emb).to(device)\n",
    "                \n",
    "    def Euclidean_intra(self,feats,targets):\n",
    "        \n",
    "        M_intra = self.M_emb\n",
    "        D = losses.euclidean_distance(feats,M_intra)\n",
    "        N = feats.size(0)\n",
    "                       \n",
    "        is_pos = targets.expand(N, N).eq(targets.expand(N, N).t())\n",
    "        \n",
    "        target_intra = []\n",
    "        D_intra = []\n",
    "        for i in range(N):          \n",
    "            if not targets[i].item() in target_intra:\n",
    "                D_id = D[is_pos[:,i],:]            \n",
    "                target_intra.append(targets[i].item())\n",
    "                index_mean = self.clusters_labels.index(targets[i].item())\n",
    "                D_intra.append(torch.max(D_id[:,index_mean]))\n",
    "        \n",
    "        D_intra = torch.stack(D_intra)\n",
    "        D_intra = D_intra.to(device)\n",
    "        return target_intra, D_intra\n",
    "    \n",
    "    def Euclidean_inter(self,targets):\n",
    "        M_intra = self.M_emb\n",
    "        N = targets.size(0)\n",
    "        is_neg = targets.expand(N, N).ne(targets.expand(N, N).t())\n",
    "        target_inter = []\n",
    "        D_inter= []\n",
    "        for i in range(N):\n",
    "            if not targets[i].item() in target_inter:\n",
    "                index_mean = self.clusters_labels.index(targets[i].item())\n",
    "                M = M_intra[index_mean,:]  \n",
    "                target_inter.append(targets[i].item())  \n",
    "                list_inter = []\n",
    "                for j in range(len(M_intra)):\n",
    "                    if not j == index_mean:\n",
    "                        X = (M_intra[j,:])\n",
    "                        list_inter.append(torch.pairwise_distance(M.unsqueeze(1),X.unsqueeze(1),2))\n",
    "                D_inter.append(torch.min(torch.stack(list_inter)))\n",
    "\n",
    "        \n",
    "        D_inter = torch.Tensor(D_inter)\n",
    "        D_inter = D_inter.to(device)\n",
    "        D_inter.requires_grad_()\n",
    "        return target_inter, D_inter\n",
    "    \n",
    "    def classification(self, feats):\n",
    "        M_intra = self.M_emb\n",
    "        D = losses.euclidean_distance(feats,M_intra)\n",
    "        N = feats.size(0)\n",
    "        classification = []\n",
    "        for j in range(N):\n",
    "            classification.append((D[j,:] == torch.min(D[j,:])).nonzero())\n",
    "            \n",
    "        return classification\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = MiniBatch_generator_2.mini_batch(folderDataset, dataset_transform,0.8)\n",
    "criterion = ClusterLoss()\n",
    "#compute the mean embedding value\n",
    "with torch.no_grad():\n",
    "    for batch_id, (in_train, labels_train) in enumerate(dataLoader_generator):\n",
    "        in_train = in_train.to(device)    \n",
    "        emb_train = model(in_train)\n",
    "        criterion.mean_feats(emb_train.squeeze(),labels_train)\n",
    "    criterion.mean_feats_compute()  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "loss_list = []\n",
    "start = time.time()\n",
    "for epoch in range(n_epochs): \n",
    "    print('epoch {}:{}'.format(epoch+1, n_epochs)) \n",
    "    loss_list_b = []\n",
    "    for batch_id, (in_a,labels)  in enumerate(dataLoader_generator):\n",
    "        int_a = Variable(in_a)\n",
    "        in_a = in_a.to(device)\n",
    "        labels = labels.to(device)\n",
    "        model.train()\n",
    "        emb_a = model(in_a)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(emb_a.squeeze(),labels)\n",
    "\n",
    "        if batch_id%10==0:\n",
    "            print(\"loss per batch {}\".format(loss))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_list_b.append(loss)\n",
    "    loss_list.append(sum(loss_list_b)/batch_id)\n",
    "#torch.save(model.state_dict(), os.path.join(PATH,str(epoch)))\n",
    "end = time.time()\n",
    "print('Training time: {} s'.format(end - start))\n",
    "print('mean time per epoch: {} s'.format((end - start)/(n_epochs - 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(criterion.M_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for batch_id, (in_train, labels_train) in enumerate(dataLoader_generator):\n",
    "        in_train = in_train.to(device)    \n",
    "        emb_train = model(in_train)\n",
    "        criterion.mean_feats(emb_train.squeeze(),labels_train)\n",
    "    criterion.mean_feats_compute()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(criterion.M_emb)\n",
    "print(criterion.M_emb.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = np.arange(1,n_epochs+1)\n",
    "plt.plot(epochs, loss_list, color='pink')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.title('Training phase')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@@@@@@@@@@@@@@@@@@@@@@@@@@@@TEST@@@@@@@@@@@@@@@@@@@@@@@@@@@@@#\n",
    "\n",
    "for batch_id, (in_a_test,labels_test)  in enumerate(dataLoader_generator_test):\n",
    "\n",
    "    in_a_test = in_a_test.to(device)\n",
    "    labels_test = labels_test.to(device)\n",
    "    emb_a_test = model(in_a_test)\n",
    "        \n",
    "    loss_test = criterion(emb_a_test.squeeze(),labels_test)\n",
    "\n",
    "    if batch_id%10==0:\n",
    "        print(\"loss per batch {}\".format(loss_test))\n",
    "        \n",
    "    classification_test = criterion.classification(emb_a_test.squeeze())\n",
    "\n",
    "        \n",
    "    #classification = torch.stack(classification).squeeze()\n",
    "    print(classification_test)\n",
    "    print(labels_test)\n",
    "    print(torch.sum(torch.eq(classification_test,labels_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_test)\n",
    "print(labels_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
