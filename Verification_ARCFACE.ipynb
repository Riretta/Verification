{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import csv\n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import time\n",
    "import os\n",
    "import pathlib\n",
    "import copy\n",
    "from datetime import date\n",
    "\n",
    "import import_ipynb\n",
    "import ResNetCaps_E\n",
    "import MiniBatch_generator\n",
    "import losses\n",
    "import CHIMP_DataLoader\n",
    "import ArcMarginProduct\n",
    "\n",
    "ATET_use = False\n",
    "LFW_use = False\n",
    "CHIM_use = True\n",
    "\n",
    "#single model selected for loading\n",
    "pick_model = -1\n",
    "#bool for loading previous model\n",
    "load_model = False\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------DATASET INITIALIZATION -----------------------------------------------------\n",
    "if ATET_use:\n",
    "    folder = 'ATET'\n",
    "    dataset_folder = \"ATeT_faces/orl_faces/\"\n",
    "if LFW_use:\n",
    "    folder = 'LFW'\n",
    "    dataset_folder = \"lfw/\"\n",
    "if CHIM_use:\n",
    "    folder = 'CHIM'\n",
    "    dataset_folder = \"chimpanzee_faces-master/datasets_cropped_chimpanzee_faces/data_CZoo/annotations_czoo.txt\"   \n",
    "    \n",
    "\n",
    "dataset_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),        \n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
    "])\n",
    "\n",
    "dataset_folder = os.path.join(\"/home/rita/JupyterProjects/EYE-SEA/DataSets/Verification\", dataset_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------DATASET LOADING----------------------------------------------------\n",
    "#dimension mini_batch\n",
    "percent = 0.2\n",
    "\n",
    "if CHIM_use:\n",
    "    print('Loading chimp dataset')\n",
    "    dataset = CHIMP_DataLoader.Chimp_Dataset(dataset_folder,dataset_transform,percent,hold_out=True)\n",
    "    dataset_t = CHIMP_DataLoader.Chimp_Dataset(dataset_folder,dataset_transform,percent,train=False)\n",
    "else:\n",
    "    print('Loading {} dataset'.format(folder))\n",
    "    dataset = MiniBatch_generator.mini_batch(dataset_folder, dataset_transform,percent)\n",
    "#num of classes of the dataset\n",
    "out_feat = len(dataset.num_ind_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------MODEL LOADER ---------------------------------- \n",
    "\n",
    "PATH= os.path.join(os.getcwd(),os.path.join('Log_model/ARCFACE',folder,'DIGIT/',(date.today()).isoformat()))\n",
    "pathlib.Path(PATH).mkdir(parents=True, exist_ok=True)\n",
    "if len(os.listdir(PATH)) > 2 and load_model:\n",
    "    print('Loading model from PATH: {}'.format(PATH))\n",
    "    model = ResNetCaps_E.ResNetCaps_E(DigitEnd=False)\n",
    "    if pick_model == -1:\n",
    "        init = len(os.listdir(PATH))-2        \n",
    "        model.load_state_dict(torch.load(os.path.join(PATH,str(init))))\n",
    "    else:\n",
    "        model.load_state_dict(torch.load(os.path.join(PATH,str(pick_model))))\n",
    "        init = pick_model\n",
    "    model.eval()\n",
    "else:\n",
    "    print('Creating a new model')\n",
    "    init=0\n",
    "    model = ResNetCaps_E.ResNetCaps_E(DigitEnd=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------Preparation of model-------------------------------------\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "    model = nn.DataParallel(model)\n",
    "    \n",
    "model = model.to(device)\n",
    "\n",
    "print(out_feat)\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "margin = ArcMarginProduct.ArcMarginProduct(in_feature=16,out_feature=out_feat, s=32)\n",
    "margin = margin.to(device)\n",
    "optimizer = optim.SGD([{'params': model.parameters(), 'weight_decay': 5e-4},\n",
    "                {'params': margin.parameters(), 'weight_decay': 5e-4}], lr=0.001, momentum=0.9, nesterov=True)\n",
    "#optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------TRAINING PHASE ----------------------------------minibatch organised random everyepoch\n",
    "\n",
    "n_epochs = 100\n",
    "loss_list_b = []\n",
    "\n",
    "for epoch in range(n_epochs): \n",
    "    print('epoch {}:{}'.format(epoch+1, n_epochs)) \n",
    "    model.train()\n",
    "    loss_collect = 0\n",
    "    in_a,labels = dataset.prepare_batch()\n",
    "    in_a = torch.stack(in_a)\n",
    "    in_a = in_a.to(device)\n",
    "    labels = torch.Tensor(labels).to(device)\n",
    "    \n",
    "    #Compute embeddings for anchor, positive, and negative images\n",
    "\n",
    "    emb_a = model(in_a)\n",
    "    emb_a = emb_a.view(in_a.size(0),-1)\n",
    "   \n",
    "    output = margin(emb_a,labels.long())\n",
    "    \n",
    "    loss = criterion(output, labels.long())\n",
    "    optimizer.zero_grad()\n",
    "    loss_collect +=loss.item()\n",
    "\n",
    "    print(\"lost per batch {}\".format(loss))\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_list_b.append(loss)\n",
    "    torch.save(model.state_dict(), os.path.join(PATH,str(epoch)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = np.arange(1,n_epochs+1)\n",
    "plt.plot(epochs, loss_list_b, color='pink')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.title('Training phase')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Phase (has to be the same for all the verification loss methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_threshold(var,percentile):\n",
    "    hist, bin_edges = np.histogram(var,100)\n",
    "    cdf = np.float32(np.cumsum(hist))/np.sum(hist)\n",
    "    bin_centers = (bin_edges[:-1]+bin_edges[1:])/2\n",
    "    threshold = np.interp(percentile*0.01, cdf, bin_centers)    \n",
    "    return threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = []\n",
    "with torch.no_grad():\n",
    "    for i in range(10):\n",
    "        in_a,_ = dataset.prepare_batch()\n",
    "        in_a = torch.stack(in_a)\n",
    "        in_a = in_a.to(device)\n",
    "        emb_a = model(in_a)  \n",
    "        D = losses.euclidean_distance(emb_a.squeeze(),emb_a.squeeze()) #criterion.M_emb)\n",
    "        #print(D)\n",
    "        v = torch.zeros(D.size(0)).to(device).type(D.dtype)\n",
    "        mask = torch.diag(torch.ones_like(v)).to(device).type(D.dtype)\n",
    "        D_m = (mask * torch.diag(v) + (1. - mask) * D).cpu().detach().numpy()\n",
    "        D_m = D_m[~np.eye(D_m.shape[0],dtype=bool)].reshape(D_m.shape[0],D_m.shape[1] - 1)\n",
    "        thresholds.append(find_threshold(D_m,0.025))\n",
    "    print(np.max(thresholds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(thresholds)\n",
    "torch.set_printoptions(threshold=100000)\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%TEST%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "model.eval()\n",
    "in_a_test,labels_test = dataset.prepare_batch_test()\n",
    "in_a_test = torch.stack(in_a_test)\n",
    "in_a_test = in_a_test.to(device)\n",
    "labels_test = torch.Tensor(labels_test).to(device)\n",
    "emb_a = model(in_a_test)\n",
    "\n",
    "D = (losses.euclidean_distance(emb_a.squeeze(),emb_a.squeeze()))\n",
    "#D_m = D[~np.eye(D.shape[0],dtype=int)].reshape(D.shape[0],-1)\n",
    "v = torch.zeros(D.size(0)).to(device).type(D.dtype)\n",
    "mask = torch.diag(torch.ones_like(v)).to(device).type(D.dtype)\n",
    "D_m = (mask * torch.diag(v) + (1. - mask) * D).cpu().detach().numpy()\n",
    "b = (D_m < np.mean(thresholds)).astype(int)\n",
    "\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(feats,labels,threshold):\n",
    "    D = losses.euclidean_distance(feats,feats)\n",
    "    N = D.size(0)\n",
    "    print(N)\n",
    "    # shape [N, N]\n",
    "    is_pos = labels.expand(N, N).eq(labels.expand(N, N).t())\n",
    "    is_neg = labels.expand(N, N).ne(labels.expand(N, N).t())\n",
    "    \n",
    "    # Exclude selfs for positive samples\n",
    "    device = labels.device\n",
    "    v = torch.zeros(N).to(device).type(is_pos.dtype)\n",
    "    mask = torch.diag(torch.ones_like(v)).to(device).type(is_pos.dtype)\n",
    "    is_pos = mask * torch.diag(v) + (1. - mask) * is_pos\n",
    "\n",
    "    # `dist_ap` means distance(anchor, positive)\n",
    "    dist_ap = D[is_pos].contiguous().view(N, -1)\n",
    "    # `dist_an` means distance(anchor, negative)\n",
    "    dist_an = D[is_neg].contiguous().view(N, -1)\n",
    "    \n",
    "    #threshold = torch.mean(dist_ap) + (torch.mean(dist_an) - torch.mean(dist_ap))/2\n",
    "    \n",
    "    positives_True =  0\n",
    "    for i in dist_ap:\n",
    "        for j in range(len(i)):\n",
    "            if i[j].item() < threshold: positives_True += 1 \n",
    "    negatives_True =  0\n",
    "    for i in dist_an:\n",
    "        for j in range(len(i)):\n",
    "            if i[j].item() > threshold: negatives_True += 1   \n",
    "    \n",
    "    VAL = positives_True/dist_ap.numel()\n",
    "    FAR = negatives_True/dist_an.numel()\n",
    "    \n",
    "    return positives_True, negatives_True, VAL, FAR, threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_a,labels = dataset.prepare_batch_test()\n",
    "in_a = torch.stack(in_a)\n",
    "in_a = in_a.to(device)\n",
    "labels = torch.Tensor(labels).to(device)\n",
    "emb_a = model(in_a)\n",
    "loss = criterion(emb_a.squeeze(),labels.long())\n",
    "P_T, N_T, VAL, FAR,th = accuracy(emb_a.squeeze(),labels,np.max(thresholds))\n",
    "print(\"Loss {}. Threshold {}: P_T {} N_T {} VAL {} FAR {}\".format(loss, th, P_T, N_T, VAL, FAR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
